# IntelExta Model Catalog
# This file defines all available AI models, their costs, and API configurations
# Pricing is in USD per million tokens (as of October 2025)

[metadata]
version = "1.0.0"
created_at = "2025-10-08T00:00:00Z"
description = "IntelExta verified model catalog with real-world pricing and environmental impact data"

[defaults]
nature_cost_algorithm = "simple"
fallback_cost_per_million_tokens = 10.0
fallback_nature_cost_per_million_tokens = 5.0

[nature_cost_algorithms.simple]
formula = "tokens * model.nature_cost_per_million_tokens / 1000000"
description = "Basic calculation: tokens × model nature cost factor"

[nature_cost_algorithms.energy_based]
formula = "(tokens * model.energy_kwh_per_million_tokens / 1000000) * grid_carbon_intensity"
description = "Energy consumption × carbon intensity of grid"
grid_carbon_intensity = 0.5

# ============================================================================
# PROVIDERS
# ============================================================================

[providers.internal]
name = "Internal"
description = "Built-in testing models"
requires_network = false
requires_api_key = false

[providers.ollama]
name = "Ollama"
description = "Local LLM inference with Ollama"
requires_network = false
requires_api_key = false
api_base_url = "http://localhost:11434"

[providers.anthropic]
name = "Anthropic"
description = "Claude models by Anthropic"
requires_network = true
requires_api_key = true
api_base_url = "https://api.anthropic.com/v1"

[providers.openai]
name = "OpenAI"
description = "GPT models by OpenAI"
requires_network = true
requires_api_key = true
api_base_url = "https://api.openai.com/v1"

[providers.google]
name = "Google"
description = "Gemini models by Google"
requires_network = true
requires_api_key = true
api_base_url = "https://generativelanguage.googleapis.com/v1beta"

[providers.groq]
name = "Groq"
description = "Ultra-fast LLM inference"
requires_network = true
requires_api_key = true
api_base_url = "https://api.groq.com/openai/v1"

[providers.xai]
name = "xAI"
description = "Grok models by xAI"
requires_network = true
requires_api_key = true
api_base_url = "https://api.x.ai/v1"

# ============================================================================
# INTERNAL MODELS
# ============================================================================

[[models]]
id = "stub-model"
provider = "internal"
display_name = "Stub Model (Testing)"
api_name = "stub-model" # Internal models can just use their ID
description = "Deterministic testing model with fixed responses"
cost_per_million_tokens = 100.0
nature_cost_per_million_tokens = 110.0
energy_kwh_per_million_tokens = 120.0
enabled = true
requires_network = false
requires_api_key = false
tags = ["testing", "internal"]

# ============================================================================
# OLLAMA MODELS (Local)
# ============================================================================

# [[models]]
# id = "llama3.2:1b"
# provider = "ollama"
# display_name = "Llama 3.2 1B (Local)"
# api_name = "llama3.2:1b" # Ollama models use their ID as the name
# description = "Small, fast local model. Good for testing and simple tasks"
# cost_per_million_tokens = 0.0
# nature_cost_per_million_tokens = 0
# energy_kwh_per_million_tokens = 0
# enabled = true
# requires_network = false
# requires_api_key = false
# tags = ["local", "ollama", "small"]
# 
# [[models]]
# id = "llama3.2:3b"
# provider = "ollama"
# display_name = "Llama 3.2 3B (Local)"
# api_name = "llama3.2:3b"
# description = "Balanced local model. Good quality with reasonable speed"
# cost_per_million_tokens = 0.0
# nature_cost_per_million_tokens = 7.5
# energy_kwh_per_million_tokens = 0.15
# enabled = true
# requires_network = false
# requires_api_key = false
# tags = ["local", "ollama", "medium"]
# 
# [[models]]
# id = "llama3.2"
# provider = "ollama"
# display_name = "Llama 3.2 (Local)"
# api_name = "llama3.2"
# description = "Latest Llama 3.2 model running locally"
# cost_per_million_tokens = 0.0
# nature_cost_per_million_tokens = 10.0
# energy_kwh_per_million_tokens = 0.20
# enabled = true
# requires_network = false
# requires_api_key = false
# tags = ["local", "ollama"]

# ============================================================================
# ANTHROPIC MODELS (Claude)
# ============================================================================

[[models]]
id = "claude-3-5-sonnet-20241022"
provider = "anthropic"
display_name = "Claude 3.5 Sonnet (New)"
api_name = "claude-3-5-sonnet-20240620" # NOTE: Using the official API name from June
description = "Most intelligent Claude model. Best for complex tasks"
cost_per_million_tokens = 9.0  # Blended ($3 input + $15 output average)
nature_cost_per_million_tokens = 12.0
energy_kwh_per_million_tokens = 0.25
context_window = 200000
max_output_tokens = 8192
enabled = true
requires_network = true
requires_api_key = true
tags = ["claude", "premium", "api"]

[[models]]
id = "claude-3-5-haiku-20241022"
provider = "anthropic"
display_name = "Claude 3.5 Haiku"
api_name = "claude-3-haiku-20240307" # NOTE: Using the official API name from March
description = "Fastest Claude model. Good for simple tasks"
cost_per_million_tokens = 2.4  # Blended ($0.80 input + $4 output average)
nature_cost_per_million_tokens = 5.0
energy_kwh_per_million_tokens = 0.10
context_window = 200000
max_output_tokens = 8192
enabled = true
requires_network = true
requires_api_key = true
tags = ["claude", "fast", "api"]

[[models]]
id = "claude-3-opus-20240229"
provider = "anthropic"
display_name = "Claude 3 Opus"
api_name = "claude-3-opus-20240229"
description = "Previous flagship model. Excellent for complex reasoning"
cost_per_million_tokens = 45.0 # Blended ($15 input + $75 output average)
nature_cost_per_million_tokens = 50.0
energy_kwh_per_million_tokens = 1.0
context_window = 200000
max_output_tokens = 4096
enabled = true
requires_network = true
requires_api_key = true
tags = ["claude", "premium", "reasoning", "api"]

# ============================================================================
# OPENAI MODELS
# ============================================================================

[[models]]
id = "gpt-4o"
provider = "openai"
display_name = "GPT-4o"
api_name = "gpt-4o"
description = "OpenAI's most advanced multimodal model"
cost_per_million_tokens = 6.25 # Blended ($2.50 input + $10 output average)
nature_cost_per_million_tokens = 10.0
energy_kwh_per_million_tokens = 0.20
context_window = 128000
max_output_tokens = 16384
enabled = true
requires_network = true
requires_api_key = true
tags = ["gpt", "multimodal", "api"]

[[models]]
id = "gpt-4o-mini"
provider = "openai"
display_name = "GPT-4o Mini"
api_name = "gpt-4o-mini"
description = "Affordable and intelligent small model"
cost_per_million_tokens = 0.375 # Blended ($0.15 input + $0.60 output average)
nature_cost_per_million_tokens = 3.0
energy_kwh_per_million_tokens = 0.06
context_window = 128000
max_output_tokens = 16384
enabled = true
requires_network = true
requires_api_key = true
tags = ["gpt", "affordable", "api"]

[[models]]
id = "gpt-4-turbo"
provider = "openai"
display_name = "GPT-4 Turbo"
api_name = "gpt-4-turbo"
description = "Previous generation GPT-4 with large context"
cost_per_million_tokens = 20.0 # Blended ($10 input + $30 output average)
nature_cost_per_million_tokens = 25.0
energy_kwh_per_million_tokens = 0.50
context_window = 128000
max_output_tokens = 4096
enabled = true
requires_network = true
requires_api_key = true
tags = ["gpt", "premium", "api"]

[[models]]
id = "gpt-3.5-turbo"
provider = "openai"
display_name = "GPT-3.5 Turbo"
api_name = "gpt-3.5-turbo"
description = "Fast and affordable for simple tasks"
cost_per_million_tokens = 1.0  # Blended ($0.50 input + $1.50 output average)
nature_cost_per_million_tokens = 2.0
energy_kwh_per_million_tokens = 0.04
context_window = 16385
max_output_tokens = 4096
enabled = true
requires_network = true
requires_api_key = true
tags = ["gpt", "affordable", "fast", "api"]

# ============================================================================
# GOOGLE GEMINI MODELS
# ============================================================================

[[models]]
id = "gemini-1.5-pro"
provider = "google"
display_name = "Gemini 1.5 Pro"
api_name = "gemini-1.5-pro-latest" # Google often uses a 'latest' tag
description = "Google's most capable model with huge context window"
cost_per_million_tokens = 3.125 # Blended ($1.25 input + $5 output average)
nature_cost_per_million_tokens = 8.0
energy_kwh_per_million_tokens = 0.16
context_window = 2000000
max_output_tokens = 8192
enabled = true
requires_network = true
requires_api_key = true
tags = ["gemini", "long-context", "api"]

[[models]]
id = "gemini-1.5-flash"
provider = "google"
display_name = "Gemini 1.5 Flash"
api_name = "gemini-1.5-flash-latest"
description = "Fast and efficient for most tasks"
cost_per_million_tokens = 0.1875 # Blended ($0.075 input + $0.30 output average)
nature_cost_per_million_tokens = 2.0
energy_kwh_per_million_tokens = 0.04
context_window = 1000000
max_output_tokens = 8192
enabled = true
requires_network = true
requires_api_key = true
tags = ["gemini", "fast", "api"]

# ============================================================================
# GROQ MODELS (Ultra-fast inference)
# ============================================================================

[[models]]
id = "groq-llama-3.1-70b"
provider = "groq"
display_name = "Llama 3.1 70B (Groq)"
api_name = "llama-3.1-70b-instant"
description = "Ultra-fast inference for Llama 3.1 70B"
cost_per_million_tokens = 0.69  # Blended ($0.59 input + $0.79 output average)
nature_cost_per_million_tokens = 4.0
energy_kwh_per_million_tokens = 0.08
context_window = 32768
max_output_tokens = 8192
enabled = true
requires_network = true
requires_api_key = true
tags = ["groq", "fast", "llama", "api"]

[[models]]
id = "groq-llama-3.1-8b"
provider = "groq"
display_name = "Llama 3.1 8B (Groq)"
api_name = "llama-3.1-8b-instant"
description = "Extremely fast small model on Groq"
cost_per_million_tokens = 0.065 # Blended ($0.05 input + $0.08 output average)
nature_cost_per_million_tokens = 1.0
energy_kwh_per_million_tokens = 0.02
context_window = 8192
max_output_tokens = 8192
enabled = true
requires_network = true
requires_api_key = true
tags = ["groq", "fast", "affordable", "api"]

[[models]]
id = "groq-mixtral-8x7b"
provider = "groq"
display_name = "Mixtral 8x7B (Groq)"
api_name = "mixtral-8x7b-32768" # This is a common API name for this model on Groq
description = "Fast MoE model on Groq infrastructure"
cost_per_million_tokens = 0.24 # Same for input and output
nature_cost_per_million_tokens = 3.0
energy_kwh_per_million_tokens = 0.06
context_window = 32768
max_output_tokens = 8192
enabled = true
requires_network = true
requires_api_key = true
tags = ["groq", "moe", "api"]

# ============================================================================
# XAI MODELS (Grok)
# ============================================================================

[[models]]
id = "grok-beta"
provider = "xai"
display_name = "Grok Beta"
# Please verify the correct API name from xAI's documentation
api_name = ""
description = "xAI's Grok model with real-time knowledge"
cost_per_million_tokens = 10.0 # Blended ($5 input + $15 output average)
nature_cost_per_million_tokens = 15.0
energy_kwh_per_million_tokens = 0.30
context_window = 131072
max_output_tokens = 4096
enabled = true
requires_network = true
requires_api_key = true
tags = ["grok", "realtime", "api"]